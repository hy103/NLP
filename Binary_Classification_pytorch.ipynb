{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiikSG9HVxfnrykiA9EHsh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hy103/NLP/blob/main/Binary_Classification_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc83bW7hiBKb",
        "outputId": "877cae7e-7b3f-4a37-9670-2c4effa28fff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pytorch mlp for binary classification\n",
        "from numpy import vstack\n",
        "from pandas import read_csv\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torch import Tensor\n",
        "from torch.nn import Linear\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import Sigmoid\n",
        "from torch.nn import Module\n",
        "from torch.optim import SGD\n",
        "from torch.nn import BCELoss\n",
        "from torch.nn.init import kaiming_uniform_\n",
        "from torch.nn.init import xavier_uniform_"
      ],
      "metadata": {
        "id": "o4cQmsl_imxN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom dataset class\n",
        "class CSVDataset(Dataset):\n",
        "  #load the datset\n",
        "  def __init__(self, path):\n",
        "    df = read_csv(path, header = None)\n",
        "    self.X = df.values[:, :-1]\n",
        "    self.y = df.values[:, -1]\n",
        "    self.X = self.X.astype('float32')\n",
        "    self.y = LabelEncoder().fit_transform(self.y)\n",
        "    self.y = self.y.astype('float32')\n",
        "    self.y = self.y.reshape((len(self.y), 1))\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __get_item__(self, idx):\n",
        "    return [self.X[idx], self.y[idx]]\n",
        "\n",
        "  def get_splits(self, n_test=0.3):\n",
        "    test_size = round(n_test* len(self.X))\n",
        "    train_size = len(self.X) - test_size\n",
        "\n",
        "    return random_split(self, [train_size, test_size])\n",
        "\n"
      ],
      "metadata": {
        "id": "lCvmnclEiGKy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Module definition\n",
        "# MLP clas\n",
        "class MLP(Module):\n",
        "  # define model elements\n",
        "  def __init__(self, n_inputs):\n",
        "    super(MLP, self).__init__()\n",
        "\n",
        "    # input to first hidden layer\n",
        "    self.hidden1 = Linear(n_inputs, 10)\n",
        "    kaiming_uniform_(self.hidden1.weight, nonlinearity = 'relu')\n",
        "    self.act1 = ReLU()\n",
        "\n",
        "    # Second hidden layer\n",
        "    self.hidden2 = Linear(10,8)\n",
        "    kaiming_uniform_(self.hidden2.weight, nonlinearity = 'relu')\n",
        "    self.act2 = ReLU()\n",
        "\n",
        "    # Third hidden layer\n",
        "    self.hidden3 = Linear(8,1)\n",
        "    kaiming_uniform_(self.hidden3.weight, nonlinearity = 'relu')\n",
        "    self.act3 = Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      #input to first hidden layer\n",
        "      X = self.hidden1(X)\n",
        "      X = self.act1(X)\n",
        "      #input to first hidden layer\n",
        "      X = self.hidden2(X)\n",
        "      X = self.act2(X)\n",
        "      #input to first hidden layer\n",
        "      X = self.hidden3(X)\n",
        "      X = self.act3(X)\n",
        "      return X"
      ],
      "metadata": {
        "id": "1GrpXAEuln-t"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare datset\n",
        "def prepare_data(path):\n",
        "  dataset = CSVDataset(path)  \n",
        "  train, test = dataset.get_splits()\n",
        "\n",
        "  train_dl = DataLoader(train, batch_size = 32, shuffle = True)\n",
        "  test_dl = DataLoader(test, batch_size= 1024, shuffle = False)\n",
        "  return train_dl, test_dl\n",
        "\n",
        "# train the model\n",
        "def train_model(train_dl, model):\n",
        "    # define the optimization\n",
        "    criterion = BCELoss()\n",
        "    optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "    # enumerate epochs\n",
        "    for epoch in range(100):\n",
        "        # enumerate mini batches\n",
        "        for i, (inputs, targets) in enumerate(train_dl):\n",
        "            # clear the gradients\n",
        "            optimizer.zero_grad()\n",
        "            # compute the model output\n",
        "            yhat = model(inputs)\n",
        "            # calculate loss\n",
        "            loss = criterion(yhat, targets)\n",
        "            # credit assignment\n",
        "            loss.backward()\n",
        "            # update model weights\n",
        "            optimizer.step()\n",
        "\n",
        "def evaluate_model(test_dl, model):\n",
        "  predictions, actuals = list(), list() \n",
        "  for i, (inputs, targets) in enumerate(test_dl):\n",
        "    yhat = model(inputs)\n",
        "    yhat = yhat.detach().numpy()\n",
        "    actual = targets.numpy()\n",
        "    actual = actual.reshape((len(actual), 1))\n",
        "    yhat = yhat.round()\n",
        "    predictions.append(yhat)\n",
        "    actuals.append(actual)\n",
        "  predictions, actuals = vstack(predictions), vstack(actuals)\n",
        "  acc = accuracy_score(actuals, predictions)\n",
        "  return acc\n",
        "\n",
        "\n",
        "\n",
        "def predict(row, model):\n",
        "  row = Tensor([row])\n",
        "  yhat = model(row)\n",
        "  yhat = yhat.detach().numpy()\n",
        "  return yhat\n"
      ],
      "metadata": {
        "id": "lshkKt_ctyAA"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'\n",
        "\n",
        "train_dl, test_dl = prepare_data(path)\n",
        "print(len(train_dl.dataset), len(test_dl.dataset))\n",
        "# define the network\n",
        "model = MLP(34)\n",
        "train_model(train_dl, model)\n",
        "acc = evaluate_model(test_dl, model)\n",
        "print('Accuracy : %.3f' %acc)\n",
        "# make a single prediction (expect class=1)\n",
        "row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n",
        "yhat = predict(row, model)\n",
        "print('Predicted: %.3f (class=%d)' % (yhat, yhat.round()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtfNiHW70DRq",
        "outputId": "9d8d0c77-a7af-40cf-8b03-629017cc8715"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "235 116\n",
            "Accuracy : 0.897\n",
            "Predicted: 0.992 (class=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p-b9HFgO13RN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}