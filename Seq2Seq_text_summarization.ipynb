{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFhz1xxa3sGdJEOYpp5ZDg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hy103/NLP/blob/main/Seq2Seq_text_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5l5jINeKg_u",
        "outputId": "f5fceb01-2fa3-42f4-fac3-00e1ef5d2adf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U nltk # To Upgrade NLTK to >3.5 for METEOR score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OM6u8JvKKiMJ",
        "outputId": "21948190-9ae2-4bae-e03b-b21afa8762f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "print('The nltk version is {}.'.format(nltk.__version__)) # Verify version >3.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCuK0bJCKnl4",
        "outputId": "50f691dc-b2f5-474c-be64-c0491d75bc63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The nltk version is 3.8.1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "HI_FFjobKqGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "summary = pd.read_csv('/content/drive/MyDrive/Seq2Seq/text_summarization/data/news_summary.csv', encoding='iso-8859-1')\n",
        "raw = pd.read_csv('/content/drive/MyDrive/Seq2Seq/text_summarization/data/news_summary_more.csv', encoding='iso-8859-1')"
      ],
      "metadata": {
        "id": "UIHZZd7jKuio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "bLqNJ8xQMKNn",
        "outputId": "73d72c23-b812-47fe-c83f-d2ff07b8978b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               author                  date  \\\n",
              "0        Chhavi Tyagi  03 Aug 2017,Thursday   \n",
              "1         Daisy Mowke  03 Aug 2017,Thursday   \n",
              "2      Arshiya Chopra  03 Aug 2017,Thursday   \n",
              "3       Sumedha Sehra  03 Aug 2017,Thursday   \n",
              "4  Aarushi Maheshwari  03 Aug 2017,Thursday   \n",
              "\n",
              "                                           headlines  \\\n",
              "0  Daman & Diu revokes mandatory Rakshabandhan in...   \n",
              "1  Malaika slams user who trolled her for 'divorc...   \n",
              "2  'Virgin' now corrected to 'Unmarried' in IGIMS...   \n",
              "3  Aaj aapne pakad liya: LeT man Dujana before be...   \n",
              "4  Hotel staff to get training to spot signs of s...   \n",
              "\n",
              "                                           read_more  \\\n",
              "0  http://www.hindustantimes.com/india-news/raksh...   \n",
              "1  http://www.hindustantimes.com/bollywood/malaik...   \n",
              "2  http://www.hindustantimes.com/patna/bihar-igim...   \n",
              "3  http://indiatoday.intoday.in/story/abu-dujana-...   \n",
              "4  http://indiatoday.intoday.in/story/sex-traffic...   \n",
              "\n",
              "                                                text  \\\n",
              "0  The Administration of Union Territory Daman an...   \n",
              "1  Malaika Arora slammed an Instagram user who tr...   \n",
              "2  The Indira Gandhi Institute of Medical Science...   \n",
              "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...   \n",
              "4  Hotels in Maharashtra will train their staff t...   \n",
              "\n",
              "                                               ctext  \n",
              "0  The Daman and Diu administration on Wednesday ...  \n",
              "1  From her special numbers to TV?appearances, Bo...  \n",
              "2  The Indira Gandhi Institute of Medical Science...  \n",
              "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...  \n",
              "4  Hotels in Mumbai and other Indian cities are t...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8edfc116-fd58-45fb-a03e-832c100f55cc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>date</th>\n",
              "      <th>headlines</th>\n",
              "      <th>read_more</th>\n",
              "      <th>text</th>\n",
              "      <th>ctext</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Chhavi Tyagi</td>\n",
              "      <td>03 Aug 2017,Thursday</td>\n",
              "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in...</td>\n",
              "      <td>http://www.hindustantimes.com/india-news/raksh...</td>\n",
              "      <td>The Administration of Union Territory Daman an...</td>\n",
              "      <td>The Daman and Diu administration on Wednesday ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Daisy Mowke</td>\n",
              "      <td>03 Aug 2017,Thursday</td>\n",
              "      <td>Malaika slams user who trolled her for 'divorc...</td>\n",
              "      <td>http://www.hindustantimes.com/bollywood/malaik...</td>\n",
              "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
              "      <td>From her special numbers to TV?appearances, Bo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Arshiya Chopra</td>\n",
              "      <td>03 Aug 2017,Thursday</td>\n",
              "      <td>'Virgin' now corrected to 'Unmarried' in IGIMS...</td>\n",
              "      <td>http://www.hindustantimes.com/patna/bihar-igim...</td>\n",
              "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
              "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sumedha Sehra</td>\n",
              "      <td>03 Aug 2017,Thursday</td>\n",
              "      <td>Aaj aapne pakad liya: LeT man Dujana before be...</td>\n",
              "      <td>http://indiatoday.intoday.in/story/abu-dujana-...</td>\n",
              "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
              "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Aarushi Maheshwari</td>\n",
              "      <td>03 Aug 2017,Thursday</td>\n",
              "      <td>Hotel staff to get training to spot signs of s...</td>\n",
              "      <td>http://indiatoday.intoday.in/story/sex-traffic...</td>\n",
              "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
              "      <td>Hotels in Mumbai and other Indian cities are t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8edfc116-fd58-45fb-a03e-832c100f55cc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8edfc116-fd58-45fb-a03e-832c100f55cc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8edfc116-fd58-45fb-a03e-832c100f55cc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pre1 =  raw.iloc[:,0:2].copy()\n",
        "# pre1['head + text'] = pre1['headlines'].str.cat(pre1['text'], sep =\" \")\n",
        "\n",
        "pre2 = summary.iloc[:,0:6].copy()\n",
        "pre2['text'] = pre2['author'].str.cat(pre2['date'].str.cat(pre2['read_more'].str.cat(pre2['text'].str.cat(pre2['ctext'], sep = \" \"), sep =\" \"),sep= \" \"), sep = \" \")"
      ],
      "metadata": {
        "id": "FNO6MEIjMnW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre = pd.DataFrame()\n",
        "pre['text'] = pd.concat([pre1['text'], pre2['text']], ignore_index=True)\n",
        "pre['summary'] = pd.concat([pre1['headlines'],pre2['headlines']],ignore_index = True)"
      ],
      "metadata": {
        "id": "qWeuL7_nNBDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "BfawgKlzND-g",
        "outputId": "8c32be9d-9d3b-4d78-c59e-ae6265966de4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...   \n",
              "1  Kunal Shah's credit card bill payment platform...   \n",
              "\n",
              "                                             summary  \n",
              "0  upGrad learner switches to career in ML & Al w...  \n",
              "1  Delhi techie wins free food from Swiggy for on...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a8962cc-dcbf-42f0-b28f-c0fccc20bb88\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
              "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
              "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a8962cc-dcbf-42f0-b28f-c0fccc20bb88')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4a8962cc-dcbf-42f0-b28f-c0fccc20bb88 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4a8962cc-dcbf-42f0-b28f-c0fccc20bb88');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pre['text'][0:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zO8KRGAxNFvu",
        "outputId": "e8c80790-9dac-448c-eaf4-53f6c7910193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Saurav Kant, an alumnus of upGrad and IIIT-B's...\n",
              "1    Kunal Shah's credit card bill payment platform...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pre['summary'][0:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDVsZ48aNLLv",
        "outputId": "4b83f36a-609d-42c9-b5d0-648df0374e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    upGrad learner switches to career in ML & Al w...\n",
              "1    Delhi techie wins free food from Swiggy for on...\n",
              "Name: summary, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "#Removes non-alphabetic characters:\n",
        "def text_strip(column):\n",
        "    for row in column:\n",
        "\n",
        "        #ORDER OF REGEX IS VERY VERY IMPORTANT!!!!!!\n",
        "\n",
        "        row=re.sub(\"(\\\\t)\", ' ', str(row)).lower() #remove escape charecters\n",
        "        row=re.sub(\"(\\\\r)\", ' ', str(row)).lower()\n",
        "        row=re.sub(\"(\\\\n)\", ' ', str(row)).lower()\n",
        "\n",
        "        row=re.sub(\"(__+)\", ' ', str(row)).lower()   #remove _ if it occors more than one time consecutively\n",
        "        row=re.sub(\"(--+)\", ' ', str(row)).lower()   #remove - if it occors more than one time consecutively\n",
        "        row=re.sub(\"(~~+)\", ' ', str(row)).lower()   #remove ~ if it occors more than one time consecutively\n",
        "        row=re.sub(\"(\\+\\++)\", ' ', str(row)).lower()   #remove + if it occors more than one time consecutively\n",
        "        row=re.sub(\"(\\.\\.+)\", ' ', str(row)).lower()   #remove . if it occors more than one time consecutively\n",
        "\n",
        "        row=re.sub(r\"[<>()|&©ø\\[\\]\\'\\\",;?~*!]\", ' ', str(row)).lower() #remove <>()|&©ø\"',;?~*!\n",
        "\n",
        "        row=re.sub(\"(mailto:)\", ' ', str(row)).lower() #remove mailto:\n",
        "        row=re.sub(r\"(\\\\x9\\d)\", ' ', str(row)).lower() #remove \\x9* in text\n",
        "        row=re.sub(\"([iI][nN][cC]\\d+)\", 'INC_NUM', str(row)).lower() #replace INC nums to INC_NUM\n",
        "        row=re.sub(\"([cC][mM]\\d+)|([cC][hH][gG]\\d+)\", 'CM_NUM', str(row)).lower() #replace CM# and CHG# to CM_NUM\n",
        "\n",
        "\n",
        "        row=re.sub(\"(\\.\\s+)\", ' ', str(row)).lower() #remove full stop at end of words(not between)\n",
        "        row=re.sub(\"(\\-\\s+)\", ' ', str(row)).lower() #remove - at end of words(not between)\n",
        "        row=re.sub(\"(\\:\\s+)\", ' ', str(row)).lower() #remove : at end of words(not between)\n",
        "\n",
        "        row=re.sub(\"(\\s+.\\s+)\", ' ', str(row)).lower() #remove any single charecters hanging between 2 spaces\n",
        "\n",
        "        #Replace any url as such https://abc.xyz.net/browse/sdf-5327 ====> abc.xyz.net\n",
        "        try:\n",
        "            url = re.search(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)', str(row))\n",
        "            repl_url = url.group(3)\n",
        "            row = re.sub(r'((https*:\\/*)([^\\/\\s]+))(.[^\\s]+)',repl_url, str(row))\n",
        "        except:\n",
        "            pass #there might be emails with no url in them\n",
        "\n",
        "\n",
        "\n",
        "        row = re.sub(\"(\\s+)\",' ',str(row)).lower() #remove multiple spaces\n",
        "\n",
        "        #Should always be last\n",
        "        row=re.sub(\"(\\s+.\\s+)\", ' ', str(row)).lower() #remove any single charecters hanging between 2 spaces\n",
        "\n",
        "\n",
        "\n",
        "        yield row"
      ],
      "metadata": {
        "id": "AzErO22mNNNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "brief_cleaning1 = text_strip(pre['text'])\n",
        "brief_cleaning2 = text_strip(pre['summary'])"
      ],
      "metadata": {
        "id": "y2bNh72QADEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = []\n",
        "while 1:\n",
        "    a.append(\"1\")\n"
      ],
      "metadata": {
        "id": "LzQqkgX3GKaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
        "\n",
        "#Taking advantage of spaCy .pipe() method to speed-up the cleaning process:\n",
        "#If data loss seems to be happening(i.e len(text) = 50 instead of 75 etc etc) in this cell , decrease the batch_size parametre\n",
        "\n",
        "t = time()\n",
        "\n",
        "#Batch the data points into 5000 and run on all cores for faster preprocessing\n",
        "text = [str(doc) for doc in nlp.pipe(brief_cleaning1, batch_size=5000)]\n",
        "\n",
        "#Takes 7-8 mins\n",
        "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "0aCqfnE-AFlm",
        "outputId": "2de626f8-9bc7-4dc4-a932-6134dfcc33d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4148486b9821>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#Batch the data points into 5000 and run on all cores for faster preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrief_cleaning1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#Takes 7-8 mins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'brief_cleaning1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = time()\n",
        "\n",
        "#Batch the data points into 5000 and run on all cores for faster preprocessing\n",
        "summary = ['_START_ '+ str(doc) + ' _END_' for doc in nlp.pipe(brief_cleaning2, batch_size=5000)]\n",
        "\n",
        "#Takes 7-8 mins\n",
        "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "metadata": {
        "id": "e_n9zfW4AIen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre['cleaned_text'] = pd.Series(text)\n",
        "pre['cleaned_summary'] = pd.Series(summary)"
      ],
      "metadata": {
        "id": "L1AGozn3AKcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_count = []\n",
        "summary_count = []"
      ],
      "metadata": {
        "id": "sm0xpemRBuGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in pre['cleaned_text']:\n",
        "    text_count.append(len(sent.split()))\n",
        "for sent in pre['cleaned_summary']:\n",
        "    summary_count.append(len(sent.split()))"
      ],
      "metadata": {
        "id": "HzhwUBRdBxBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_df= pd.DataFrame()\n",
        "graph_df['text']=text_count\n",
        "graph_df['summary']=summary_count"
      ],
      "metadata": {
        "id": "Jeoc_D9qBxF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "graph_df.hist(bins = 5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m7xtop7yBxJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check how much % of summary have 0-15 words\n",
        "cnt=0\n",
        "for i in pre['cleaned_summary']:\n",
        "    if(len(i.split())<=15):\n",
        "        cnt=cnt+1\n",
        "print(cnt/len(pre['cleaned_summary']))"
      ],
      "metadata": {
        "id": "2jHm-iwnBxMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check how much % of text have 0-70 words\n",
        "cnt=0\n",
        "for i in pre['cleaned_text']:\n",
        "    if(len(i.split())<=100):\n",
        "        cnt=cnt+1\n",
        "print(cnt/len(pre['cleaned_text']))"
      ],
      "metadata": {
        "id": "jAVS2ExKBxPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model to summarize the text between 0-15 words for Summary and 0-100 words for Text\n",
        "max_text_len=100\n",
        "max_summary_len=15"
      ],
      "metadata": {
        "id": "1gB2LZSVBxR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Select the Summaries and Text between max len defined above\n",
        "\n",
        "cleaned_text =np.array(pre['cleaned_text'])\n",
        "cleaned_summary=np.array(pre['cleaned_summary'])\n",
        "\n",
        "short_text=[]\n",
        "short_summary=[]\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_summary.append(cleaned_summary[i])\n",
        "\n",
        "post_pre=pd.DataFrame({'text':short_text,'summary':short_summary})"
      ],
      "metadata": {
        "id": "S6zU7WUhB4jX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_pre.head(2)"
      ],
      "metadata": {
        "id": "UkYClMUiB4mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add sostok and eostok at\n",
        "post_pre['summary'] = post_pre['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
      ],
      "metadata": {
        "id": "Foif6ooaB4pS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(np.array(post_pre['text']),np.array(post_pre['summary']),test_size=0.1,random_state=0,shuffle=True)"
      ],
      "metadata": {
        "id": "hVUzOl3vB4sE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets tokenize the text to get the vocab count , you can use Spacy here also\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer()\n",
        "x_tokenizer.fit_on_texts(list(x_tr))"
      ],
      "metadata": {
        "id": "YMfYNZYAB4we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thresh=4\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in x_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "\n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "metadata": {
        "id": "xEc8Vgp5B4ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt)\n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences (i.e one-hot encodeing all the words)\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr)\n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
        "\n",
        "#size of vocabulary ( +1 for padding token)\n",
        "x_voc   =  x_tokenizer.num_words + 1\n",
        "\n",
        "print(\"Size of vocabulary in X = {}\".format(x_voc))"
      ],
      "metadata": {
        "id": "CQDIs4WIB40J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer()\n",
        "y_tokenizer.fit_on_texts(list(y_tr))"
      ],
      "metadata": {
        "id": "yStg0iRlB428"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thresh=6\n",
        "\n",
        "cnt=0\n",
        "tot_cnt=0\n",
        "freq=0\n",
        "tot_freq=0\n",
        "\n",
        "for key,value in y_tokenizer.word_counts.items():\n",
        "    tot_cnt=tot_cnt+1\n",
        "    tot_freq=tot_freq+value\n",
        "    if(value<thresh):\n",
        "        cnt=cnt+1\n",
        "        freq=freq+value\n",
        "\n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "metadata": {
        "id": "cSxdOqzvB45s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt)\n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert text sequences into integer sequences (i.e one hot encode the text in Y)\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr)\n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
        "\n",
        "#size of vocabulary\n",
        "y_voc  =   y_tokenizer.num_words +1\n",
        "print(\"Size of vocabulary in Y = {}\".format(y_voc))"
      ],
      "metadata": {
        "id": "ADU707A6B47x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind=[]\n",
        "for i in range(len(y_tr)):\n",
        "    cnt=0\n",
        "    for j in y_tr[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_tr=np.delete(y_tr,ind, axis=0)\n",
        "x_tr=np.delete(x_tr,ind, axis=0)"
      ],
      "metadata": {
        "id": "-vZCU92bBxWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind=[]\n",
        "for i in range(len(y_val)):\n",
        "    cnt=0\n",
        "    for j in y_val[i]:\n",
        "        if j!=0:\n",
        "            cnt=cnt+1\n",
        "    if(cnt==2):\n",
        "        ind.append(i)\n",
        "\n",
        "y_val=np.delete(y_val,ind, axis=0)\n",
        "x_val=np.delete(x_val,ind, axis=0)"
      ],
      "metadata": {
        "id": "LMTm9zY9BxYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "import gensim\n",
        "from numpy import *\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"Size of vocabulary from the w2v model = {}\".format(x_voc))\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "latent_dim = 300\n",
        "embedding_dim=200\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_text_len,))\n",
        "\n",
        "#embedding layer\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
        "\n",
        "#encoder lstm 1\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
        "\n",
        "#encoder lstm 2\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
        "\n",
        "#encoder lstm 3\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "#embedding layer\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
        "\n",
        "#dense layer\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "7BwPUEE3CKpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "metadata": {
        "id": "sQ-1cOckCKs8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
      ],
      "metadata": {
        "id": "aEZFKvJgCKv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "metadata": {
        "id": "nF_4LTDqCKys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "wwegsSaeCK11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\n",
        "reverse_source_word_index=x_tokenizer.index_word\n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "metadata": {
        "id": "vRvD4tK5CK4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h2, state_c2])\n"
      ],
      "metadata": {
        "id": "jREA_ohuCK7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "\n",
        "    # Populate the first word of target sequence with the start word.\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "\n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "aBSr0oQ4CK-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "metadata": {
        "id": "hIuSdHBbCLBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,100):\n",
        "    print(\"Review:\",seq2text(x_tr[i]))\n",
        "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "SfeNIrWHCLER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hdQlKhOECLHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I15-Un0YCLKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "orCajw2PCLNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1uKLIz0ZCLQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i_67u91qBxat"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}